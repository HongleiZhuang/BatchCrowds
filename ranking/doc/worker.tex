%!TEX root=betamain.tex

\section{Crowdsourcing Worker Annotation Model on Batches}
%\section{Worker Annotation Model On Small Batch of Data}
\label{sec:worker}

In this section, we first describe our model for workers' annotation behavior 
on a batch of data items;
then we introduce how to train the model based on a training data set.
%finally we presents the parameters of this model learned from a real world data set.

Our key intuition is the follows:
when a worker judges a batch of data items,
she can either:
1) choose to judge data items independently as if they are presented alone; or
2) to rank all the data items according to their relative inherent scores
and annotate the top several items as positive, leaving the rest in the batch as negative.

%

\vpara{Plackett-Luce model.}
Before we delve into our model, we first recap a probability model for generating rankings
based on scores associated with items, 
namely the classical Plackett-Luce model~\cite{luce:2005, plackett:1975} introduced in the 70s.
Without loss of generality, suppose we are given a set of items $x_1, \ldots, x_k$.
Each item $x_i$ is associated with a certain score $s(x_i) > 0$.  %\reminder{example needed here.}
Here the score $s(x_i)$ models the tendency of ranking 
$x_i$ higher in a randomly generated ranking and 
can be viewed as a measure of the inherent ``goodness'' of the item.
A ranking of these items can be represented as a bijection $\pi : \{i\}_{i = 1}^k \mapsto \{x_i\}_{i = 1}^k$,
that maps the $i$ to the data item at the $i$-th position in the ranking.
%\agp{Doesn't this map $i$ to item at position $i$ in the ranking?} 
The corresponding ranking list can be represented as
$\pi(1) \succ \cdots \succ \pi(k)$.
In Plackett-Luce model, the probability of generating a ranking $\pi$ is:
\beal{\label{eq:plmodel}
P(\pi) = \prod_{i = 1}^k \frac{s(x_i)}{\sum_{r = i}^{k} s(x_r)}	
}%
The equation above can be interpreted as the following process:
Initially, we have a pool $A$ of all the data items.
Each time one picks an item $x_i$ from a pool $A$ of data 
items with a probability proportional to its score, namely:
\beal{
P(\text{picking $x_i$ from $A$}) = \frac{s(x_i)}{\sum_{x_r \in A} s(x_r)} \nonumber
}
This item is then removed from the pool $A$ and placed at the next position in the ranking.
Repeat this operation until $A$ becomes empty.
The probability of generating a ranking list according to this process is equivalent to the probability described in the Plackett-Luce model.

%

\vpara{Worker model.}
We now introduce our worker model for annotating batches of data items.
Again, without loss of generality, suppose we are given a batch $\bx_j$ where $x_{jl} = x_l$,
namely the given data item batch can be denoted as $\bx_j=\{x_1, \ldots, x_k\}$.
 %of $(x_1, \ldots, x_k)$, namely $b_{ji} = i$.pp
Also, recall that for each data item $x_i$, we denote $P(y_i = 1 | x_i)$ as its inherent score $\eta_i$,
which is not explicitly known. 
%\agp{It's odd to call this a predictive probability. Isn't
%this a measure of goodness or inherent value?}
%Although this value is not explicitly known,
%we assume the worker has the ability to estimate this value based on the features of data item.

When a worker starts to work on a certain batch of data items,
they may choose to use one of two strategies:
\begin{itemize}
  \item \emph{Independent judging.}
  If the worker is making judgments based on the absolute value of $\eta_i$ for each data item, 
  %\agp{Why does the ability of obtaining an estimate matter? confused..}
  we suppose the worker judges each data item $x_i \in \bx_j$ independently
  by drawing the annotation $y_i'=1$ with probability $\eta_i$ and $y_i' = 0$ with probability $(1 - \eta_i)$.
  \item \emph{Relative judging.}
  If the worker is making judgments by comparing data items within the same batch
  %If the worker can only tell the relative propensity of whether a data item is more likely to be positively labeled than another data item 
  %\agp{This is not dependent on the items right -- this is a random coin toss, it seems to indicate that it is dependent on the items..},
  without knowing absolute value of $\eta_i$,
  we suppose the worker chooses to first rank all the data items based on their probability of being positive,
  then annotates the top-$\tau$ items in the ranking as positive, leaving the other items annotated as negative.
  To be precise, the worker generates a ranking $\pi$ for $k$ items in the batch according to the Plackett-Luce model,
  with the scoring function defined as $s(x_i) = \eta_i$.
  Then the worker draws an integer $0 \leq \tau \leq k$ from a certain distribution,
  where $p_\tau$ denotes the probability of drawing the integer $\tau$.
  For data items ranked as top-$\tau$ in the ranking,
  denoted as $x_i \in \{\pi(1), \ldots, \pi(\tau)\}$ (could be empty if $\tau = 0$),
  the worker annotates them as $y_i'=1$,
  while other data items not within the top-$\tau$ of the ranking $\pi$ are annotated as $y_i' = 0$.
\end{itemize}
To combine these two different scenarios,
we suppose the worker is able to judge independently with a certain probability $0 < \lambda < 1$,
while with probability $(1-\lambda)$ the worker can only make relative judgments.

\hide{
the worker chooses to judge each data item $x_i$ independently based on the $\eta_i$ value.
More concretely, the worker generates $y_i' = 1$ with probability $\eta_i$ and $y_i' = 0$ with probability $(1 - \eta_i)$.
With probability $(1 - \lambda)$, the worker chooses to first rank all the data items based on their probability of being positive,
then annotates the top-$\tau$ items in the ranking as positive, leaving the other items annotated as negative.
To be precise, the worker generates a ranking $\pi$ for $k$ items in the batch according to the Plackett-Luce model,
with the scoring function defined as $s(x_i) = \eta_i$.
Then the worker draws an integer $0 \leq \tau \leq k$ from a certain distribution,
where $p_\tau$ denotes the probability of drawing the integer $\tau$.
For data items $x_i \in \{\pi^{-1}(1), \ldots, \pi^{-1}(p)\}$ (could be empty if $p = 0$), the worker annotates them as $y_i'=1$,
while other data items not within the top-$p$ of the ranking $\pi$ are annotated as $y_i' = 0$.
}

The intuition of this model is to capture two behavior pattern of workers.
In the independent judging scenario,
workers can remain independent in judging different data items in the same batch,
with each data item being judged based on its inherent score $\eta_i$.
%use an absolute standard to judge data items from different batches,p
%and therefore remain consistent performance.
Nevertheless, sometimes workers might judge data items 
within a batch by comparison.
In the relative judging scenario,
workers simply judge the relative 
relationships between data items in the same batch,
which is captured by the Plackett-Luce model for generating the ranking.
In order to determine the labels of data items,
they have an expectation of label distribution,
which is reflected by the distribution of generating $\tau$,
as it characterizes the probability of having $\tau$ positives within $k$ data items.
For instance, if workers expect
there to be few positive items, then the probability of $\tau$
being low is high, while if workers expect
the batches to be balanced, then the probability of $\tau$ being close to
$k/2$ is high comparing to other values of $\tau$.
However, this distribution does not necessarily 
reflect the correct label distribution.
When they try to apply their expectation 
of the label distribution on the batch, bias might occur.

We summarize the process of generating annotation for a batch of data items in our proposed model as below:

\begin{enumerate}
  \item \label{step:tosscoin}
        Toss a coin $Z \sim Bernoulli(\lambda)$.  \\
        If $Z=1$, go to Step~\ref{step:ind};
        otherwise go to Step~\ref{step:rnk}.
  \item \label{step:ind}
        For each $x_i$, generate $y_i' \sim Bernoulli(\eta_i)$. \\
        Output the results and exit.
  \item \label{step:rnk}
        Generate a ranking $\pi$ based on Plackett-Luce model for data items $x_i$ in the batch.
  \item \label{step:draw}
        Draw $\tau \sim Mult(p_{\tau})$.
  \item \label{step:annotate}
        For the top-$\tau$ items in ranking $\pi$, generate $y_i' = 1$; \\
        otherwise generate $y_i' = 0$.  \\
        Output the results and exit.
\end{enumerate}



\vpara{Model learning.}
The parameters that need to be determined in this worker model include:
the probability of making independent judgments $\lambda$,
and the distribution of the number of positive annotation when making relative judgments,
represented by $p_0, \ldots, p_k$, where $0 \leq p_{\tau} \leq 1$ and $\sum p_{\tau} = 1$.
We assume these two parameters are fixed for each new application of our techniques.  
However, for different applications, these parameters might be different --- for instance, 
these parameters for content moderation may be different from the same parameters for spam identification or sentiment analysis.  


% independent of the data items in question.
% \agp{check:(Or at least, we assume that the two parameters are fixed
% for each new application of our techniques ---
% for instance, these parameters for content moderation
% may be very different from the same parameters for
% spam identification or sentiment analysis).}


Suppose we are given a set of $n_L$ items $X_L$ with their true labels $Y_L$, 
or more ideally, their inherent scores $\{\eta_i\}_{x_i \in X_L}$.  
If the inherent score of a data item $\eta_i$ is not given, 
but only the binary label $y_i$ is known,
we can estimate $\eta_i$ by $\eta_i = (y_i + \epsilon)/(1 + 2 \epsilon)$ 
where $\epsilon$ is a small constant, which is set to $10^{-3}$ in our experiments.
%predictive distribution \agp{wasn't this inherent value? just checked -- it's not} $\eta_i$ known. %true labels $Y_L$ known.p
Then, we form them into $m_L$ batches $B_L$, send them to the crowds,
and obtain their annotation from workers, denoted as $Y_{B_L}'$.



%For simplicity, we write $x_{b_{jt}}$ as $x_{jt}$, and similar to $y_{jt}$ and $\eta_{jt}$.
For each batch $\bb_j \in B_L$, we denote the set of items annotated by workers as positive as $X_{j}^1 = \{x_{jt} | y_{jt}' = 1\}$,
and the set of items annotated as negative as $X_{j}^0 = \{x_{jt} | y_{jt}' = 0\}$.


We train the model by maximum likelihood estimation.
The likelihood of the obtained annotation can be written as:
\beal{
	L = %\overbrace{\prod_{j=1}^{m_L}}^{\text{across all batches}} \biggl[p
        \prod_{j=1}^{m_L} \biggl[
		\lambda \underbrace{
            \prod_{t=1}^{k} \eta_{jt}^{y_{jt}} (1 - \eta_{jt})^{(1 - y_{jt})}
        }_{\text{independent judging}}
		%\prod_{x_{jt1} \in X_{j}^1} \eta_{jt1} \prod_{x_{jt0} \in X_{j}^0} (1 - \eta_{jt0}) \nonumber \\
		+ (1 - \lambda) \underbrace{
            p_{\tau_j} P(X_{j}^1 \succ X_{j}^0)
        }_{\text{relative judging}}
	\biggr]
}%
where $\tau_j = |X_{j}^1|$ is the number of positive annotation in batch $b_j$;
$P(X_{j}^1 \succ X_{j}^0)$ denotes the probability of generating any rankings $\pi$
that rank items in $X_{j}^1$ higher than any items in $X_{j}^0$,
namely:
\beal{
	P(X_{j}^1 \succ X_{j}^0) = \sum_{\pi \in R(X_{j}^1, X_{j}^0)} P(\pi) \nonumber
}%
where $R(X_1, X_0) = \{ \pi |\pi^{-1}(x_{0}) > \pi^{-1}(x_{1}),  \forall x_{1} \in X_1, x_0 \in X_0 \}$;
and $P(\pi)$ is defined by the Plackett-Luce model, as presented in~\eqref{eq:plmodel}.  
Notice that the calculation of the exact value of $P(X_{j}^1 \succ X_{j}^0)$ is hard when $k$ is large.  
In our experiments, $k$ is small enough to enumerate entire set $R(X_{j}^1, X_{j}^0)$.  
If $k$ is large, we can apply Monte Carlo method to estimate the value of $P(X_{j}^1 \succ X_{j}^0)$.  

Applying an EM-algorithm, where at E-step, we can have
\beal{ \label{eq:e_step}
	\hat{\lambda}_j = \frac{\hat{\lambda} \prod_{t=1}^{k} \eta_{jt}^{y_{jt}} (1 - \eta_{jt})^{(1 - y_{jt})}}
	{\hat{\lambda} \prod_{t=1}^{k} \eta_{jt}^{y_{jt}} (1 - \eta_{jt})^{(1 - y_{jt})} +
	(1 - \hat{\lambda}) \hat{p}_{\tau_j} P(X_{j}^1 \succ X_{j}^0)}
}

And at M-step, we update the parameters $\hat{\lambda}$ and $\hat{p}_{\tau}$ by
\beal{ \label{eq:m_step}
	\hat{\lambda} = \frac{1}{m_L}\sum_{j=1}^{m_L} \hat{\lambda}_j, \hspace{0.2in}
	\hat{p}_{\tau} = \frac{1}{\hat{Z}} \sum_{j=1}^{m_L} (1 - \hat{\lambda}_j) \mathbf{1}_{\{ |X_{j}^1| = \tau\}}
}%
where $\hat{Z} = \sum_{j=1}^{m_L} (1 - \hat{\lambda}_j)$.

\hide{
However, in real data sets, we do not always know $\eta_i$ for each data item $x_i$,
but only know their binary true labels $Y_L$.
We can still learn the worker model based on this situation
by substituting their labels $y_i \in \{0, 1\}$ into $\eta_i$.
Directly substituting the value of 0 or 1 into $\eta_i$ may cause numerical problems in calculating $\lambda_j$.
Therefore we regularize the score by using:
\beal{
	\eta_i = \frac{y_i + \epsilon}{1 + 2 \epsilon} \nonumber
}%
where $\epsilon$ is a small constant which is set to $10^{-3}$ in our experiments.
}




